import torch
import torch . nn as nn
import torch . optim as optim
from torch . utils . data import DataLoader
import torchvision . transforms as transforms
from torchvision import models
from sklearn.cluster import KMeans
import torchvision . datasets as datasets

print("PyTorch version:", torch.__version__)
print("CUDA version in PyTorch:", torch.version.cuda)
print("CUDA available:", torch.cuda.is_available())
print("Number of GPUs:", torch.cuda.device_count())
print("GPU name:", torch.cuda.get_device_name(0) if torch.cuda.is_available() else "None")


from datasets import load_dataset

dataset = load_dataset("ylecun/mnist")

train_dataset = dataset["train"]
test_dataset = dataset["test"]

input_size = 784
hidden_size = 128
output_size = 10 
learning_rate = 0.001
batch_size = 64
epochs = 5


transform = transforms . Compose ([
            transforms . ToTensor () ,
            transforms . Normalize ((0.5 ,) , (0.5 ,) )
])

train_dataset = datasets.MNIST(
    root='./data',
    train=True,
    transform=transform,
    download=True
)

test_dataset = datasets.MNIST(
    root='./data',
    train=False,
    transform=transform
)

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)

import matplotlib.pyplot as plt
image = dataset['train'][1]['image']
label = dataset['train'][5]['label']
plt.imshow(image, cmap="grey")
plt.title(f"Label: {label}")
plt.show()

class Autoencoder(nn.Module):
    def __init__(self, latent_dim=64):
        super(Autoencoder, self).__init__()

        self.encoder = nn.Sequential(
            nn.Conv2d(1, 32, 3, stride=2, padding=1),   
            nn.ReLU(),
            nn.Conv2d(32, 64, 3, stride=2, padding=1),  
            nn.ReLU(),
            nn.Conv2d(64, 128, 3, stride=2, padding=1), 
            nn.ReLU()
        )

        self.flatten = nn.Flatten()
        self.fc_latent = nn.Linear(128 * 4 * 4, latent_dim)

       
        self.fc_decode = nn.Linear(latent_dim, 128 * 4 * 4)
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), 
            nn.ReLU(),
            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1),  
            nn.ReLU(),
            nn.ConvTranspose2d(32, 1, 3, stride=2, padding=1, output_padding=1),   
            nn.Sigmoid()
        )

    def encode(self, x):
        x = self.encoder(x)
        x = self.flatten(x)
        z = self.fc_latent(x)
        return z

    def decode(self, z):
        x = self.fc_decode(z)
        x = x.view(-1, 128, 4, 4)
        x = self.decoder(x)
        x = x[:, :, :28, :28]  
        return x

    def forward(self, x):
        z = self.encode(x)
        x_recon = self.decode(z)
        return x_recon
		
		

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = Autoencoder(latent_dim=64).to(device)

optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
criterion = nn.MSELoss()


for epoch in range(epochs):
    model.train()
    total_loss = 0
    for images, _ in train_loader:
        images = images.to(device)
        outputs = model(images)
        loss = criterion(outputs, images)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    print(f"Epoch {epoch+1}/{epochs} - Loss: {total_loss/len(train_loader):.4f}")
	
	

model.eval()
latent_features = []
labels = []

with torch.no_grad():
    for images, lbls in train_loader:
        images = images.to(device)
        z = model.encode(images)
        latent_features.append(z.cpu())
        labels.append(lbls)

latent_features = torch.cat(latent_features).numpy()
labels = torch.cat(labels).numpy()


import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE


tsne = TSNE(n_components=2, perplexity=30, random_state=42)
features_2d = tsne.fit_transform(latent_features)


plt.figure(figsize=(10, 8))
sns.scatterplot(
    x=features_2d[:, 0],
    y=features_2d[:, 1],
    hue=labels,
    palette="tab10",
    legend="full",
    s=60,
    alpha=0.8
)

plt.title("t-SNE Visualization of Latent Space")
plt.xlabel("t-SNE 1")
plt.ylabel("t-SNE 2")
plt.legend(title="Digit Label", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()



from sklearn.cluster import KMeans
from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score


n_clusters = 10  
kmeans = KMeans(n_clusters=n_clusters, random_state=42)
cluster_preds = kmeans.fit_predict(latent_features)


ari = adjusted_rand_score(labels, cluster_preds)
nmi = normalized_mutual_info_score(labels, cluster_preds)

print(f"K-Means clustering results:")
print(f"Adjusted Rand Index (ARI): {ari:.4f}")
print(f"Normalized Mutual Information (NMI): {nmi:.4f}")


import matplotlib.pyplot as plt
from sklearn.manifold import TSNE

tsne = TSNE(n_components=2, perplexity=30, random_state=42)
features_2d = tsne.fit_transform(latent_features)

plt.figure(figsize=(8, 6))
plt.scatter(features_2d[:, 0], features_2d[:, 1], c=cluster_preds, cmap="tab10", s=10)
plt.colorbar()
plt.title("t-SNE Visualization of Clusters")
plt.show()


def count_module_params(module):
    return sum(p.numel() for p in module.parameters() if p.requires_grad)


total_params = count_module_params(model)


encoder_params = count_module_params(model.encoder)

latent_params = count_module_params(model.fc_latent) + count_module_params(model.fc_decode)


decoder_params = count_module_params(model.decoder)


print(f"Total Trainable Parameters: {total_params}")
print(f" - Encoder Parameters (Conv layers): {encoder_params}")
print(f" - Latent Space Parameters (Fully connected): {latent_params}")
print(f" - Decoder Parameters (Transpose Conv layers): {decoder_params}")




